---
title: RAGå®æˆ˜ï¼šç”¨LangChainå¿«é€Ÿæ­å»ºä¸ªäººçŸ¥è¯†åº“
date: 2025-08-16 16:35:41
tags:
  - langchain
  - rag
typora-root-url: ./RAGå®æˆ˜ï¼šç”¨LangChainå¿«é€Ÿæ­å»ºä¸ªäººçŸ¥è¯†åº“
---

# RAGå®æˆ˜ï¼šç”¨LangChainå¿«é€Ÿæ­å»ºä¸ªäººçŸ¥è¯†åº“

# å‰è¨€

æœ¬äººåœ¨ç‰©è”ç½‘ï¼ˆIoTï¼‰ç›¸å…³é¢†åŸŸå·¥ä½œä¸€å¹´å¤šï¼Œæœ€è¿‘ä¸€ç›´åœ¨çœ‹å¤§æ¨¡å‹å’ŒMQTTç›¸å…³çš„çŸ¥è¯†ã€‚ç›¸æ¯”äºæ¯ç‡¥çš„ç†è®ºå­¦ä¹ ï¼Œæˆ‘æ›´ä¿¡å¥‰**â€œLearning by Doingâ€**ï¼Œæ‰€ä»¥æˆ‘æƒ³åˆ©ç”¨æ—¶ä¸‹å¤§ç«RAGæŠ€æœ¯æ­å»ºä¸€ä¸ªMQTTåè®®çš„ä¸ªäººçŸ¥è¯†åº“ï¼Œä¸‹é¢å°†è¯¦ç»†è®°å½•ä»ç¯å¢ƒæ­å»ºåˆ°åº”ç”¨ä¸Šçº¿çš„æ¯ä¸€æ­¥ï¼Œå±•ç¤ºä¸€ä¸ªå®Œæ•´RAGé¡¹ç›®çš„å®ç°ç»†èŠ‚ã€‚

# èƒŒæ™¯çŸ¥è¯†

## RAG ç®€ä»‹

RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢ä¸ç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨ç”Ÿæˆç­”æ¡ˆå‰ï¼Œå…ˆä»å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆå¦‚æ–‡æ¡£ã€æ•°æ®åº“ã€äº’è”ç½‘ï¼‰ä¸­æ£€ç´¢ç›¸å…³è¯æ®ï¼Œå†åŸºäºæ£€ç´¢ç»“æœå’Œç”¨æˆ·è¾“å…¥ç”Ÿæˆæ›´å‡†ç¡®ã€å¯é çš„å›ç­”ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºä¸ºä¸€ä¸ªæœ€ç®€RAGç¤ºæ„å›¾ã€‚

![å›¾ç‰‡](640.png)

ä»å½¢æ€ä¸Šè¯´ï¼ŒLLMå……å½“å¤§è„‘è§’è‰²ç”¨äºç”Ÿæˆç­”æ¡ˆï¼Œæ£€ç´¢å……å½“è§¦æ‰‹è§’è‰²ç”¨äºæ”¶é›†è¯æ®ã€‚RAGå°±æ˜¯ä¸€ä¸ªå¸¦è§¦æ‰‹ï¼ˆå¤–æŒ‚çŸ¥è¯†åº“ï¼‰çš„å¤§æ¨¡å‹ç³»ç»Ÿã€‚

# ç¯å¢ƒå‡†å¤‡

## å…ˆå†³æ¡ä»¶

- **Python 3.9+**: ç¡®ä¿ç³»ç»Ÿå·²å®‰è£… Pythonã€‚
- **Docker**: è¿™æ˜¯è¿è¡Œ PostgreSQL + pgvector æœ€ç®€å•ã€æœ€æ¨èçš„æ–¹å¼ã€‚
- **OpenAI API Key**: å‰å¾€ [OpenAI å®˜ç½‘](https://platform.openai.com/api-keys) åˆ›å»ºä¸€ä¸ª API Keyã€‚ï¼ˆæ¨èç™½å«–åœ°å€ï¼šhttps://github.com/chatanywhere/GPT_API_freeï¼‰

## æ ¸å¿ƒä¾èµ–é¡¹

```
# --- Core Framework ---
langchain              # RAG æµç¨‹çš„æ ¸å¿ƒç¼–æ’æ¡†æ¶

# --- LangChain Integrations ---
langchain-postgres     # ç”¨äºä¸ PGVector æ•°æ®åº“äº¤äº’çš„æœ€æ–°ã€æ¨èåº“
langchain-openai       # ç”¨äºè¿æ¥ OpenAI çš„ LLM å’Œ Embedding æ¨¡å‹

# --- Database Driver ---
psycopg                # PostgreSQL çš„ Python æ•°æ®åº“é©±åŠ¨ç¨‹åºï¼Œä¾› langchain-postgres ä½¿ç”¨

# --- User Interface ---
gradio                 # å¿«é€Ÿæ„å»ºäº¤äº’å¼ Web UI

# --- Data Handling ---
pypdf                  # ç”¨äºåŠ è½½å’Œè§£æ PDF æ–‡æ¡£
tiktoken               # OpenAI å®˜æ–¹çš„åˆ†è¯å™¨ï¼Œç”¨äºè®¡ç®— token æ•°é‡

# --- Configuration ---
python-dotenv          # ç”¨äºä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
```

å°†ä»¥ä¸‹å†…å®¹ä¿å­˜åˆ°é¡¹ç›®çš„ `requirements.txt` æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿äºä¸€é”®å®‰è£… (`pip install -r requirements.txt`)ã€‚

## é¡¹ç›®ç»“æ„ï¼š

```sh
mqtt-rag-project/
â”œâ”€â”€ .env                              # ç¯å¢ƒå˜é‡æ–‡ä»¶
â”œâ”€â”€ app.py                            # Webåº”ç”¨ä¸é—®ç­”æœåŠ¡
â”œâ”€â”€ hivemq-ebook-mqtt-essentials.pdf  # MQTT PDF æ–‡æ¡£
â”œâ”€â”€ ingest.py                         # æ•°æ®å…¥åº“è„šæœ¬
â””â”€â”€ start-pgvector.sh                 # pgvectorçš„å¯åŠ¨è„šæœ¬
```

## pgvectorå‘é‡æ•°æ®åº“ dockerå®‰è£…

å…ˆå®‰è£…postgresqlå®¢æˆ·ç«¯

```sh
yum install postgresql
```

### start-pgvector.sh :

```sh
docker run --name pgvector-db \
  -e POSTGRES_USER=root \
  -e POSTGRES_PASSWORD=root \
  -e POSTGRES_DB=pgvector \
  -p 5432:5432 \
  -d pgvector/pgvector:pg17
```

éªŒè¯æœ‰æ²¡æœ‰æˆåŠŸå®‰è£…

```sh
psql -h localhost -p 5432 -U root pgvector
```

è¾“å…¥å¯†ç åæˆåŠŸè¿›å»å°±OKã€‚

## pgadmin å®‰è£…ï¼ˆå¯é€‰ï¼‰

å®˜ç½‘ï¼šhttps://www.pgadmin.org/download/

ä½¿ç”¨pgadminå¯è§†åŒ–çš„çœ‹åˆ°æ•°æ®åº“ä¸­çš„å‘é‡å­˜å‚¨å±•ç¤ºã€‚

# é¡¹ç›®ç»†èŠ‚ï¼š

## æ•´ä½“æµç¨‹ï¼š

è¿™æ˜¯æ•´ä¸ªé¡¹ç›®çš„å®Œæ•´å·¥ä½œæµç¨‹å›¾ï¼Œæ¸…æ™°åœ°å±•ç¤ºäº†æ•°æ®å…¥åº“å’Œç”¨æˆ·é—®ç­”ä¸¤ä¸ªé˜¶æ®µã€‚

```plantuml

@startuml

title MQTT RAG çŸ¥è¯†åº“ - å…¨æµç¨‹å›¾

actor Developer
actor User

box "ç¦»çº¿æ•°æ®å¤„ç† (Offline Ingestion)" #LightBlue
    participant "ingest.py" as Ingest
    participant "Embedding Model\n(OpenAI)" as Embed
    database "PGVector Database" as DB
end box

box "åœ¨çº¿é—®ç­”æœåŠ¡ (Online Querying)" #LightGreen
    participant "Gradio UI" as UI
    participant "LangChain RAG Chain\n(app.py)" as RAG
    participant "LLM\n(GPT-4o)" as LLM
end box


== ğŸ“– 1. æ•°æ®å…¥åº“é˜¶æ®µ (ç”± Developer æ‰§è¡Œ) ==

Developer -> Ingest: è¿è¡Œ python ingest.py
activate Ingest

Ingest -> Ingest: 1. åŠ è½½å¹¶åˆ†å‰²\n"mqtt.pdf"
Ingest -> Embed: 2. å¯¹æ¯ä¸ªæ–‡æœ¬å—\nè¯·æ±‚å‘é‡åŒ–
activate Embed
Embed --> Ingest: è¿”å›æ–‡æœ¬å‘é‡
deactivate Embed

Ingest -> DB: 3. (æ¸…ç©ºæ—§æ•°æ®å)\nå­˜å‚¨æ–‡æœ¬å—å’Œå‘é‡
activate DB
DB --> Ingest: å­˜å‚¨æˆåŠŸ
deactivate DB

Ingest --> Developer: æ‰“å° "å…¥åº“å®Œæˆ" æ—¥å¿—
deactivate Ingest


== ğŸ’¬ 2. ç”¨æˆ·é—®ç­”é˜¶æ®µ (ç”± User ä½¿ç”¨) ==

User -> UI: 1. åœ¨èŠå¤©æ¡†è¾“å…¥é—®é¢˜
activate UI
UI -> RAG: 2. å‘é€é—®é¢˜
deactivate UI
activate RAG

RAG -> Embed: 3. å°†ç”¨æˆ·é—®é¢˜å‘é‡åŒ–
activate Embed
Embed --> RAG: è¿”å›é—®é¢˜å‘é‡
deactivate Embed

RAG -> DB: 4. ä½¿ç”¨é—®é¢˜å‘é‡\nè¿›è¡Œç›¸ä¼¼åº¦æœç´¢
activate DB
DB --> RAG: 5. è¿”å›æœ€ç›¸å…³çš„\nKä¸ªæ–‡æœ¬å— (ä¸Šä¸‹æ–‡)
deactivate DB

RAG -> RAG: 6. æ„å»º Prompt:\n(ä¸Šä¸‹æ–‡ + åŸå§‹é—®é¢˜)

RAG -> LLM: 7. å‘é€å¢å¼ºåçš„ Prompt
activate LLM
LLM --> RAG: 8. **æµå¼**è¿”å›ç”Ÿæˆçš„ç­”æ¡ˆ
deactivate LLM

RAG -> UI: 9. å°†ç­”æ¡ˆ**æµå¼**ä¼ è¾“åˆ°å‰ç«¯
activate UI
UI -> User: 10. åœ¨èŠå¤©æ¡†ä¸­å®æ—¶\næ˜¾ç¤ºç­”æ¡ˆ (æ‰“å­—æœºæ•ˆæœ)
deactivate UI
deactivate RAG

@enduml

```

## .env ï¼ˆç¯å¢ƒå˜é‡ï¼‰

```
# .env æ–‡ä»¶
OPENAI_API_KEY="xxxx"
OPENAI_BASE_URL="xxxxx"
DATABASE_URL="postgresql://root:root@localhost:5432/pgvector"
```

## hivemq-ebook-mqtt-essentials.pdf(MQTTç›¸å…³çš„ä¹¦ç±)

hivemqç»„ä»¶æ¨å‡ºçš„ä¸€æœ¬mqttç›¸å…³çš„ä¹¦ç±ï¼Œéœ€è¦æŠŠè¿™æœ¬ä¹¦è§£æä¸ºçŸ¥è¯†åº“ã€‚

## ingest.py (æ•°æ®å…¥åº“è„šæœ¬)

```python
import os
import logging
import psycopg
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores.pgvector import PGVector

# --- 1. âš™ï¸ é…ç½®æ—¥å¿—ç³»ç»Ÿ ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- 2. ğŸ”‘ åŠ è½½ç¯å¢ƒå˜é‡å’Œé…ç½® ---
logging.info("ğŸš€ å¼€å§‹æ•°æ®å…¥åº“æµç¨‹...")
load_dotenv()
logging.info("âœ… .env æ–‡ä»¶åŠ è½½æˆåŠŸ")

# ä»ç¯å¢ƒå˜é‡ä¸­å®‰å…¨åœ°è·å–é…ç½®
PDF_PATH = "hivemq-ebook-mqtt-essentials.pdf"  # ä½ å¯ä»¥æŠŠå®ƒä¹Ÿæ”¾å…¥ .env
COLLECTION_NAME = "mqtt_docs"
CONNECTION_STRING = os.getenv("DATABASE_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")

# æ£€æŸ¥å…³é”®é…ç½®æ˜¯å¦å­˜åœ¨
if not all([CONNECTION_STRING, OPENAI_API_KEY, OPENAI_BASE_URL]):
    error_msg = "âŒ å…³é”®ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦åŒ…å« DATABASE_URL, OPENAI_API_KEY, OPENAI_BASE_URL"
    logging.error(error_msg)
    raise ValueError(error_msg)
logging.info("ğŸ‘ æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®åŠ è½½å®Œæ¯•")


def ingest_data():
    """
    åŠ è½½ã€åˆ†å‰²ã€åµŒå…¥å¹¶å­˜å‚¨PDFæ–‡æ¡£æ•°æ®åˆ°PGVectorã€‚
    """
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(PDF_PATH):
        logging.error(f"ğŸ”¥ é”™è¯¯: PDFæ–‡ä»¶æœªæ‰¾åˆ°äº {PDF_PATH}")
        return

    connection = None
    try:
        # --- 3. ğŸ“„ åŠ è½½PDFæ–‡æ¡£ ---
        logging.info(f"ğŸ“„ æ­£åœ¨åŠ è½½æ–‡æ¡£: {PDF_PATH}...")
        loader = PyPDFLoader(PDF_PATH)
        documents = loader.load()
        logging.info(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} é¡µæ–‡æ¡£ã€‚")

        # --- 4. ğŸ”ª åˆ†å‰²æ–‡æ¡£ä¸ºæ–‡æœ¬å— ---
        logging.info("ğŸ”ª æ­£åœ¨åˆ†å‰²æ–‡æ¡£ä¸ºæ–‡æœ¬å—...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            length_function=len
        )
        chunks = text_splitter.split_documents(documents)
        logging.info(f"âœ… æ–‡æ¡£è¢«åˆ†å‰²æˆ {len(chunks)} ä¸ªæ–‡æœ¬å—ã€‚")

        # --- 5. ğŸ§  åˆ›å»ºæ–‡æœ¬åµŒå…¥æ¨¡å‹ ---
        logging.info("ğŸ§  æ­£åœ¨åˆå§‹åŒ– OpenAI Embedding æ¨¡å‹ (text-embedding-3-small)...")
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_BASE_URL
        )
        logging.info("âœ… åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚")

        # --- 6. ğŸ“¦ å°†æ•°æ®å­˜å…¥ PGVector ---
        logging.info(f"ğŸ”— æ­£åœ¨è¿æ¥åˆ°æ•°æ®åº“: {CONNECTION_STRING.split('@')[-1]}")
        connection = psycopg.connect(CONNECTION_STRING)
        logging.info("ğŸ‰ æ•°æ®åº“è¿æ¥æˆåŠŸï¼")

        logging.info(f"ğŸ“¦ å‡†å¤‡å°† {len(chunks)} ä¸ªæ–‡æœ¬å—å­˜å…¥é›†åˆ '{COLLECTION_NAME}'...")

        # ä½¿ç”¨ from_documents æ–¹æ³•ï¼Œå¹¶è®¾ç½® pre_delete_collection=True
        # è¿™ä¼šå…ˆåˆ é™¤åŒåæ—§é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œç¡®ä¿æ•°æ®ä»é›¶å¼€å§‹ï¼Œéå¸¸é€‚åˆé‡æ–°å…¥åº“
        PGVector.from_documents(
            documents=chunks,
            embedding=embeddings,
            collection_name=COLLECTION_NAME,
            connection_string=CONNECTION_STRING,
            pre_delete_collection=True,  # âœ¨ æœ€ä½³å®è·µ: ä¿è¯æ¯æ¬¡éƒ½æ˜¯å…¨æ–°å…¥åº“
        )

        logging.info("ğŸ‰ æ•°æ®å¤„ç†æµç¨‹åœ†æ»¡å®Œæˆï¼")
        logging.info(f"âœ… {len(chunks)} ä¸ªæ–‡æ¡£å—å·²æˆåŠŸå­˜å…¥é›†åˆ '{COLLECTION_NAME}'ã€‚")

    except Exception as e:
        logging.error(f"ğŸ”¥ æ•°æ®å¤„ç†æµç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
    finally:
        # ç¡®ä¿æ•°æ®åº“è¿æ¥åœ¨ä½¿ç”¨åè¢«å…³é—­
        if connection:
            connection.close()
            logging.info("ğŸšª æ•°æ®åº“è¿æ¥å·²å…³é—­ã€‚")


if __name__ == "__main__":
    ingest_data()

```

æµç¨‹æ€»ç»“ï¼š

```mermaid
%% `ingest.py`
graph TD
    subgraph "å‡†å¤‡é˜¶æ®µ (Preparation)"
        A[å¼€å§‹ Ingestion è„šæœ¬] --> B["é…ç½®ä¸åŠ è½½<br>(Logging, .env)"];
    end

    subgraph "æ•°æ®å¤„ç† (Processing)"
        B --> C{PDF æ–‡ä»¶å­˜åœ¨?};
        C -- å¦ --> D[è®°å½•é”™è¯¯å¹¶é€€å‡º];
        C -- æ˜¯ --> E["åŠ è½½ PDF æ–‡æ¡£<br>(ä½¿ç”¨ PyPDFLoader)"];
        E --> F["åˆ†å‰²æ–‡æ¡£ä¸ºæ–‡æœ¬å— (Chunks)<br>(ä½¿ç”¨ RecursiveCharacterTextSplitter)"];
        F --> G["åˆå§‹åŒ–åµŒå…¥æ¨¡å‹<br>(OpenAI text-embedding-3-small)"];
    end
    
    subgraph "æ•°æ®åº“æ“ä½œ (Database Operations)"
        G --> H["è¿æ¥åˆ° PostgreSQL æ•°æ®åº“<br>(ä½¿ç”¨ psycopg)"];
        H --> I[è°ƒç”¨ PGVector.from_documents];
        
        subgraph I [å†…éƒ¨æµç¨‹]
            direction TB
            I1{pre_delete_collection=True?};
            I1 -- æ˜¯ --> I2[æ¸…ç©º/åˆ é™¤æ—§çš„ Collection];
            I1 -- å¦ --> I3;
            I2 --> I3["å¯¹äºæ¯ä¸€ä¸ª Chunk..."];
            I3 --> I4["è°ƒç”¨ OpenAI API<br>å°†æ–‡æœ¬è½¬æ¢ä¸º Vector"];
            I4 --> I5["å°† (æ–‡æœ¬ + Vector)<br>æ’å…¥æ•°æ®åº“"];
            I5 --> I3;
        end
    end

    subgraph "æ”¶å°¾é˜¶æ®µ (Finalization)"
         I --> J["è®°å½•æˆåŠŸæ—¥å¿—"];
         J --> K["å…³é—­æ•°æ®åº“è¿æ¥<br>(åœ¨ finally å—ä¸­ç¡®ä¿æ‰§è¡Œ)"];
         K --> L[æµç¨‹ç»“æŸ];
    end
```



è¿™ä¸ªè„šæœ¬æ˜¯ä¸€ä¸ª**ä¸€æ¬¡æ€§**çš„ã€**ç¦»çº¿**è¿è¡Œçš„ç¨‹åºï¼Œä½œç”¨å°±æ„å»ºçŸ¥è¯†åº“ã€‚

- **ğŸ¯ ç›®çš„**: å°†éç»“æ„åŒ–çš„ PDF æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–çš„ã€å¯ä¾›å¿«é€Ÿæ£€ç´¢çš„å‘é‡æ•°æ®ã€‚
- æ ¸å¿ƒæµç¨‹
  1. **åŠ è½½ (Load)**: è¯»å–æŒ‡å®šçš„ MQTT PDF æ–‡æ¡£å†…å®¹ã€‚
  2. **åˆ†å‰² (Split)**: å°†æ•´ä¸ªæ–‡æ¡£çš„é•¿æ–‡æœ¬åˆ‡å‰²æˆæ›´å°çš„ã€å¸¦æœ‰ä¸Šä¸‹æ–‡é‡å çš„æ–‡æœ¬å— (Chunks)ã€‚
  3. **åµŒå…¥ (Embed)**: è°ƒç”¨ OpenAI çš„ `text-embedding-3-small` æ¨¡å‹ï¼Œå°†æ¯ä¸€ä¸ªæ–‡æœ¬å—è½¬æ¢æˆä¸€ä¸ªé«˜ç»´æ•°å­¦å‘é‡ã€‚
  4. **å­˜å‚¨ (Store)**: å°†æ–‡æœ¬å—å’Œå…¶å¯¹åº”çš„å‘é‡ä¸€èµ·å­˜å…¥ PostgreSQL æ•°æ®åº“çš„ `pgvector` æ‰©å±•ä¸­ï¼Œå¹¶ä½¿ç”¨ `pre_delete_collection=True` ç¡®ä¿æ¯æ¬¡éƒ½æ˜¯å…¨æ–°çš„æ•°æ®ã€‚

è¿è¡Œï¼š

```sh
python ingest.py 
2025-08-16 17:17:22 - INFO - ğŸš€ å¼€å§‹æ•°æ®å…¥åº“æµç¨‹...
2025-08-16 17:17:22 - INFO - âœ… .env æ–‡ä»¶åŠ è½½æˆåŠŸ
2025-08-16 17:17:22 - INFO - ğŸ‘ æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®åŠ è½½å®Œæ¯•
2025-08-16 17:17:22 - INFO - ğŸ“„ æ­£åœ¨åŠ è½½æ–‡æ¡£: hivemq-ebook-mqtt-essentials.pdf...
2025-08-16 17:17:24 - INFO - âœ… æˆåŠŸåŠ è½½ 90 é¡µæ–‡æ¡£ã€‚
2025-08-16 17:17:24 - INFO - ğŸ”ª æ­£åœ¨åˆ†å‰²æ–‡æ¡£ä¸ºæ–‡æœ¬å—...
2025-08-16 17:17:24 - INFO - âœ… æ–‡æ¡£è¢«åˆ†å‰²æˆ 317 ä¸ªæ–‡æœ¬å—ã€‚
2025-08-16 17:17:24 - INFO - ğŸ§  æ­£åœ¨åˆå§‹åŒ– OpenAI Embedding æ¨¡å‹ (text-embedding-3-small)...
2025-08-16 17:17:24 - INFO - âœ… åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚
2025-08-16 17:17:24 - INFO - ğŸ”— æ­£åœ¨è¿æ¥åˆ°æ•°æ®åº“: localhost:5432/pgvector
2025-08-16 17:17:24 - INFO - ğŸ‰ æ•°æ®åº“è¿æ¥æˆåŠŸï¼
2025-08-16 17:17:24 - INFO - ğŸ“¦ å‡†å¤‡å°† 317 ä¸ªæ–‡æœ¬å—å­˜å…¥é›†åˆ 'mqtt_docs'...
2025-08-16 17:17:27 - INFO - HTTP Request: POST https://api.chatanywhere.tech/embeddings "HTTP/1.1 200 OK"
/usr/local/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:490: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. 
  store = cls(
2025-08-16 17:17:35 - INFO - ğŸ‰ æ•°æ®å¤„ç†æµç¨‹åœ†æ»¡å®Œæˆï¼
2025-08-16 17:17:35 - INFO - âœ… 317 ä¸ªæ–‡æ¡£å—å·²æˆåŠŸå­˜å…¥é›†åˆ 'mqtt_docs'ã€‚
2025-08-16 17:17:35 - INFO - ğŸšª æ•°æ®åº“è¿æ¥å·²å…³é—­ã€‚
```

pgvector æœ‰å‘Šè­¦æ˜¯å› ä¸º LangChain æ¨èä½¿ç”¨æ€§èƒ½æ›´å¥½çš„ `JSONB` æ ¼å¼æ¥å­˜å‚¨å…ƒæ•°æ®ã€‚

### æ•°æ®åº“å‘é‡ï¼š

ç”¨pgadminå·¥å…·å¯ä»¥çœ‹åˆ°æ•°æ®åº“é‡Œé¢åˆ›å»ºäº†2å¼ è¡¨ï¼š

![image-20250816182559256](image-20250816182559256.png)

**`langchain_pg_collection` (é›†åˆç›®å½•è¡¨)**

- **ä½œç”¨**: è®°å½•äº†ä½ åˆ›å»ºçš„æ‰€æœ‰å‘é‡é›†åˆï¼ˆCollectionsï¼‰çš„åç§°å’Œå”¯ä¸€IDã€‚
- **å†…å®¹**: æ¯è¡Œä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„çŸ¥è¯†åº“ï¼ˆä¾‹å¦‚ `mqtt_docs`ï¼‰ã€‚

**`langchain_pg_embedding` (åµŒå…¥æ•°æ®è¡¨)**

- **ä½œç”¨**: å­˜å‚¨äº†**æ‰€æœ‰é›†åˆ**çš„å…¨éƒ¨æ•°æ®ã€‚
- **å†…å®¹**: æ¯è¡ŒåŒ…å«ä¸€ä¸ªå…·ä½“çš„æ–‡æœ¬å—ï¼ˆdocumentï¼‰ã€å…¶å¯¹åº”çš„å‘é‡ï¼ˆembeddingï¼‰ä»¥åŠä¸€ä¸ª `collection_id`ï¼Œç”¨äºæŒ‡æ˜è¿™æ¡æ•°æ®å±äºå“ªä¸ªé›†åˆã€‚

```sql
CREATE TABLE IF NOT EXISTS public.langchain_pg_collection
(
    -- å­—æ®µæ³¨é‡Š --
    name      character varying,  -- é›†åˆçš„æ˜“è¯»åç§°ï¼Œç”±å¼€å‘è€…åœ¨ä»£ç ä¸­æŒ‡å®š (ä¾‹å¦‚ 'mqtt_docs')ã€‚
    cmetadata json,               -- (Collection Metadata) ç”¨äºå­˜å‚¨å…³äºæ•´ä¸ªé›†åˆçš„å…ƒæ•°æ®çš„ JSON å­—æ®µã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å­˜å‚¨é›†åˆçš„æè¿°ã€æ¥æºä¿¡æ¯ç­‰ã€‚
    uuid      uuid NOT NULL,      -- é›†åˆçš„å”¯ä¸€æ ‡è¯†ç¬¦ (UUID)ï¼Œä½œä¸ºè¿™å¼ è¡¨çš„ä¸»é”® (Primary Key)ã€‚å®ƒè¢« `langchain_pg_embedding` è¡¨ç”¨ä½œå¤–é”®æ¥å…³è”æ•°æ®ã€‚

    -- çº¦æŸæ³¨é‡Š --
    CONSTRAINT langchain_pg_collection_pkey PRIMARY KEY (uuid) -- å°† `uuid` å­—æ®µè®¾ç½®ä¸ºä¸»é”®ï¼Œç¡®ä¿æ¯ä¸ªé›†åˆéƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„ã€éç©ºçš„æ ‡è¯†ç¬¦ã€‚
);

CREATE TABLE IF NOT EXISTS public.langchain_pg_embedding
(
    -- å­—æ®µæ³¨é‡Š --
    collection_id uuid,               -- å¤–é”® (Foreign Key)ï¼Œå…³è”åˆ° `langchain_pg_collection` è¡¨ä¸­çš„ `uuid`ã€‚å®ƒæ ‡è¯†äº†è¿™æ¡æ•°æ®å±äºå“ªä¸€ä¸ªé›†åˆã€‚
    embedding     vector,             -- æ–‡æœ¬å—çš„å‘é‡è¡¨ç¤ºã€‚è¿™æ˜¯ç”± `pgvector` æ‰©å±•æä¾›çš„æ•°æ®ç±»å‹ï¼Œç”¨äºè¿›è¡Œé«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢ã€‚
    document      character varying,  -- åŸå§‹çš„æ–‡æœ¬å—å†…å®¹ã€‚è¿™æ˜¯ RAG æµç¨‹ä¸­æ£€ç´¢åˆ°çš„ã€å°†æä¾›ç»™ LLM ä½œä¸ºä¸Šä¸‹æ–‡çš„å®é™…æ–‡æœ¬ã€‚
    cmetadata     json,               -- (Content Metadata) å…³äºå•ä¸ªæ–‡æœ¬å—çš„å…ƒæ•°æ®çš„ JSON å­—æ®µã€‚é€šå¸¸ç”¨äºå­˜å‚¨æ¥æºä¿¡æ¯ (å¦‚æ–‡ä»¶åã€é¡µç ) ä»¥ä¾¿è¿½æº¯å’Œè¿‡æ»¤ã€‚è¾ƒæ–°ç‰ˆæœ¬ä¸­ï¼Œæ­¤å­—æ®µç±»å‹å·²å‡çº§ä¸º `JSONB` ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½ã€‚
    custom_id     character varying,  -- ä¸€ä¸ªå¯é€‰çš„ã€ç”±ç”¨æˆ·è‡ªå®šä¹‰çš„ ID å­—æ®µã€‚å¦‚æœå¼€å‘è€…åœ¨æ·»åŠ æ–‡æ¡£æ—¶æä¾›äº† `ids` å‚æ•°ï¼Œè¿™äº› ID ä¼šè¢«å­˜å‚¨åœ¨è¿™é‡Œï¼Œæ–¹ä¾¿ä¸å¤–éƒ¨ç³»ç»Ÿè¿›è¡Œå…³è”æˆ–è¿›è¡Œç‰¹å®š ID çš„æ•°æ®æ“ä½œã€‚
    uuid          uuid NOT NULL,      -- è¿™æ¡åµŒå…¥æ•°æ®è®°å½•è‡ªèº«çš„å”¯ä¸€æ ‡è¯†ç¬¦ (UUID)ï¼Œä½œä¸ºè¿™å¼ è¡¨çš„ä¸»é”®ã€‚

    -- çº¦æŸæ³¨é‡Š --
    CONSTRAINT langchain_pg_embedding_pkey PRIMARY KEY (uuid), -- å°† `uuid` å­—æ®µè®¾ç½®ä¸ºä¸»é”®ï¼Œç¡®ä¿è¡¨ä¸­çš„æ¯ä¸€æ¡æ•°æ®è®°å½•éƒ½æ˜¯å”¯ä¸€çš„ã€‚

    CONSTRAINT langchain_pg_embedding_collection_id_fkey FOREIGN KEY (collection_id) -- å®šä¹‰äº† `collection_id` æ˜¯ä¸€ä¸ªå¤–é”®ï¼Œå®ƒå¿…é¡»å¼•ç”¨ `langchain_pg_collection` è¡¨ä¸­çœŸå®å­˜åœ¨çš„ `uuid`ã€‚
        REFERENCES public.langchain_pg_collection (uuid) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE CASCADE -- è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„çº§è”åˆ é™¤è§„åˆ™ï¼šå½“ä¸€ä¸ªé›†åˆä» `langchain_pg_collection` è¡¨ä¸­è¢«åˆ é™¤æ—¶ï¼Œæ‰€æœ‰å±äºè¯¥é›†åˆçš„æ•°æ®å°†è‡ªåŠ¨ä»è¿™å¼ è¡¨ä¸­è¢«åˆ é™¤ï¼Œä¿è¯äº†æ•°æ®çš„å®Œæ•´æ€§ã€‚
);
```



ç”¨sqlçœ‹ä¸‹æ•°æ®:

```sh
pgvector=# select * from langchain_pg_collection;
   name    | cmetadata |                 uuid                 
-----------+-----------+--------------------------------------
 mqtt_docs | null      | 6b065562-e20d-4758-8097-8459dd3618db
(1 row)
pgvector=#  select count(*) from langchain_pg_embedding;
 count 
-------
   317
(1 row)
```

langchain_pg_embedding æ•°é‡å’Œæ—¥å¿—é‡Œé¢å¯¹çš„ä¸Šçš„ï¼Œlangchain_pg_embedding çš„è¡¨æ•°æ®å¤ªé•¿äº†ï¼Œä¸‹å›¾å±•ç¤ºä¸€ä¸‹ï¼š

![image-20250816185704062](image-20250816185704062.png)

è¿™é‡Œç›´è§‚çš„çœ‹åˆ°æ–‡æœ¬è½¬ä¸ºä¸ºå‘é‡å¹¶å­˜å‚¨åˆ°æ•°æ®åº“ä¸­äº†ã€‚

## `app.py` (Webåº”ç”¨ä¸é—®ç­”æœåŠ¡)

```python
import os
import logging
import gradio as gr
import psycopg
from dotenv import load_dotenv

from langchain_community.vectorstores.pgvector import PGVector
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.schema.output_parser import StrOutputParser

# --- 1. âš™ï¸ é…ç½®æ—¥å¿—ç³»ç»Ÿ ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- 2. ğŸ”‘ åŠ è½½ç¯å¢ƒå˜é‡å’Œé…ç½® ---
logging.info("ğŸš€ åº”ç”¨å¼€å§‹å¯åŠ¨...")
load_dotenv()
logging.info("âœ… .env æ–‡ä»¶åŠ è½½æˆåŠŸ")

CONNECTION_STRING = os.getenv("DATABASE_URL")
COLLECTION_NAME = "mqtt_docs"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")

# æ£€æŸ¥å…³é”®é…ç½®æ˜¯å¦å­˜åœ¨
if not all([CONNECTION_STRING, COLLECTION_NAME, OPENAI_API_KEY, OPENAI_BASE_URL]):
    error_msg = "âŒ å…³é”®ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦åŒ…å« DATABASE_URL, OPENAI_API_KEY, OPENAI_BASE_URL"
    logging.error(error_msg)
    raise ValueError(error_msg)
logging.info("ğŸ‘ æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®åŠ è½½å®Œæ¯•")

# --- 3. ğŸ”— åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ ---
try:
    logging.info(f"ğŸ”— æ­£åœ¨è¿æ¥åˆ°æ•°æ®åº“: {CONNECTION_STRING.split('@')[-1]}")
    connection = psycopg.connect(CONNECTION_STRING)
    logging.info("ğŸ‰ æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
except Exception as e:
    logging.error(f"ğŸ”¥ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    raise

# --- 4. ğŸ§  åˆå§‹åŒ– AI æ¨¡å‹ ---
logging.info("ğŸ§  æ­£åœ¨åˆå§‹åŒ– OpenAI æ¨¡å‹...")
llm = ChatOpenAI(
    base_url=OPENAI_BASE_URL,
    api_key=OPENAI_API_KEY,
    model="gpt-4o",
    temperature=0.1,
    streaming=True
)
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL
)
logging.info("ğŸ¤– LLM å’Œ Embedding æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

# --- 5. ğŸ“š åˆå§‹åŒ–å‘é‡å­˜å‚¨å’Œæ£€ç´¢å™¨ ---
logging.info(f"ğŸ“š æ­£åœ¨è¿æ¥åˆ°å‘é‡é›†åˆ: '{COLLECTION_NAME}'")
vectorstore = PGVector(
    connection_string=CONNECTION_STRING,
    collection_name=COLLECTION_NAME,
    embedding_function=embeddings,
)

# è¿”å›10ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
retriever = vectorstore.as_retriever(search_kwargs={'k': 10})
logging.info("âœ… å‘é‡å­˜å‚¨å’Œæ£€ç´¢å™¨å‡†å¤‡å°±ç»ª")

# --- 6. ğŸ› ï¸ æ„å»º RAG é“¾ (å¸¦æ—¥å¿—è®°å½•) ---

# æç¤ºæ¨¡æ¿
template = """
ä½ æ˜¯ä¸€ä¸ªå…³äºMQTTåè®®çš„æŠ€æœ¯ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨ä¸­æ–‡ã€æ¸…æ™°ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜â€œæ ¹æ®æˆ‘æ‰€æŒæ¡çš„çŸ¥è¯†ï¼Œæ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜â€ï¼Œä¸è¦ç¼–é€ ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡:
{context}

é—®é¢˜:
{question}

å›ç­”:
"""
prompt = PromptTemplate.from_template(template)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


def log_retrieved_documents(docs):
    """ä¸€ä¸ªç”¨äºåœ¨é“¾ä¸­è®°å½•æ£€ç´¢åˆ°çš„æ–‡æ¡£çš„å‡½æ•°"""
    logging.info(f"ğŸ” å‘é‡æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
    for i, doc in enumerate(docs):
        content_preview = doc.page_content.replace('\n', ' ').strip()[:120]
        page_num = doc.metadata.get('page', 'N/A')
        logging.info(f"  ğŸ“„ æ–‡æ¡£ {i + 1} (é¡µç : {page_num}): '{content_preview}...'")
    return docs


logging.info("â›“ï¸ æ­£åœ¨æ„å»º RAG é“¾...")
rag_chain = (
        {
            "context": retriever | RunnableLambda(log_retrieved_documents) | format_docs,
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
)
logging.info("âœ… RAG é“¾æ„å»ºå®Œæˆ")


# --- 7. ğŸ’¬ å®šä¹‰ Gradio èŠå¤©åŠŸèƒ½ ---
def chat_function(message, history):
    logging.info(f"ğŸ’¬ æ”¶åˆ°ç”¨æˆ·æ–°é—®é¢˜: '{message}'")

    # æµå¼å¤„ç†
    response_generator = rag_chain.stream(message)
    partial_message = ""
    logging.info("âœï¸ å¼€å§‹å‘ç”¨æˆ·æµå¼ä¼ è¾“å›ç­”...")
    for chunk in response_generator:
        partial_message += chunk
        yield partial_message
    logging.info("âœ… æµå¼ä¼ è¾“å®Œæˆ")


# --- 8. ğŸŒ å¯åŠ¨ Gradio åº”ç”¨ ---
if __name__ == "__main__":
    logging.info("ğŸŒ å‡†å¤‡å¯åŠ¨ Gradio Web UI...")
    demo = gr.ChatInterface(
        fn=chat_function,
        title="MQTT åè®®çŸ¥è¯†åº“ ğŸ¤–",
        description="""
        è¿™æ˜¯ä¸€ä¸ªåŸºäº MQTT åè®®æ–‡æ¡£çš„ RAG é—®ç­”æœºå™¨äººã€‚
        ä½ å¯ä»¥ç”¨ä¸­æ–‡æé—®å…³äº MQTT åè®®çš„ä»»ä½•é—®é¢˜ï¼Œä¾‹å¦‚ï¼š
        - "MQTTçš„QoSç­‰çº§æœ‰å“ªäº›ï¼Ÿåˆ†åˆ«è§£é‡Šä¸€ä¸‹ã€‚"
        - "CONNECTæŠ¥æ–‡çš„ç»“æ„æ˜¯æ€æ ·çš„ï¼Ÿ"
        - "ä»€ä¹ˆæ˜¯é—å˜±æ¶ˆæ¯ï¼ˆWill Messageï¼‰ï¼Ÿ"
        """,
        type="messages",
        chatbot=gr.Chatbot(height=600),
        textbox=gr.Textbox(placeholder="è¯·è¾“å…¥ä½ å…³äºMQTTåè®®çš„é—®é¢˜...", container=False, scale=7),
        theme="soft",
    )
    demo.launch()
```

æµç¨‹æ€»ç»“ï¼š



```mermaid
%% `app.py`
graph TD
    subgraph "é˜¶æ®µä¸€: åº”ç”¨å¯åŠ¨ä¸åˆå§‹åŒ–"
        A[å¯åŠ¨ app.py]
        A --> B["é…ç½®ä¸åŠ è½½<br>(Logging, .env)"]
        B --> C["å»ºç«‹æŒä¹…çš„<br>æ•°æ®åº“è¿æ¥ (psycopg)"]
        C --> D["åˆå§‹åŒ– AI æ¨¡å‹<br>(LLM: GPT-4o & Embeddings)"]
        D --> E["åˆå§‹åŒ–å‘é‡å­˜å‚¨<br>å¹¶åˆ›å»º Retriever"]
        E --> F["æ„å»º RAG é“¾<br>(ä½¿ç”¨ LangChain LCEL)"]
        F --> G["å¯åŠ¨ Gradio Web UI<br>(åº”ç”¨è¿›å…¥ç›‘å¬çŠ¶æ€)"]
    end

    %% æ·»åŠ ä¸€ä¸ªä»é˜¶æ®µä¸€åˆ°é˜¶æ®µäºŒçš„é€»è¾‘è¿æ¥çº¿
    G -. "ç”¨æˆ·å¼€å§‹äº¤äº’" .-> User

    subgraph "é˜¶æ®µäºŒ: å®æ—¶é—®ç­”æµç¨‹"
        User["User"]
        UI[Gradio UI]
        RAG["LangChain RAG Chain<br>(åœ¨ app.py ä¸­è¿è¡Œ)"]
        DB["PGVector Database"]
        LLM["LLM (GPT-4o)"]

        User -- 1.è¾“å…¥é—®é¢˜ --> UI
        UI -- 2.å°†é—®é¢˜å‘é€ç»™chat_function--> RAG
        RAG -- 3.å‘é‡åŒ–é—®é¢˜å¹¶æ£€ç´¢--> DB
        DB -- "4.è¿”å› K ä¸ªæœ€ç›¸å…³çš„<br>æ–‡æœ¬å— (ä¸Šä¸‹æ–‡)" --> RAG
        RAG -- "5.æ„å»ºæœ€ç»ˆ Prompt:<br>[ä¸Šä¸‹æ–‡] + [åŸå§‹é—®é¢˜]" --> LLM
        LLM -- 6.<b>æµå¼</b>ç”Ÿæˆç­”æ¡ˆ --> RAG
        RAG -- "7.å°†ç­”æ¡ˆ <b>æµå¼</b> ä¼ è¾“å› UI" --> UI
        UI -- "8.å®æ—¶æ›´æ–°èŠå¤©çª—å£<br>(æ‰“å­—æœºæ•ˆæœ)" --> User
    end
```



è¿™ä¸ªè„šæœ¬æ˜¯ä¸€ä¸ª**æŒç»­è¿è¡Œ**çš„ã€**åœ¨çº¿**æä¾›æœåŠ¡çš„ç¨‹åºï¼Œå®ƒæ„æˆäº†ç”¨æˆ·ä¸ä¹‹äº¤äº’çš„åç«¯å’Œå‰ç«¯ã€‚

- **ğŸ¯ ç›®çš„**: æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œåˆ©ç”¨å·²æ„å»ºçš„çŸ¥è¯†åº“ç”Ÿæˆç²¾å‡†å›ç­”ï¼Œå¹¶é€šè¿‡ Web ç•Œé¢å±•ç¤ºã€‚
- æ ¸å¿ƒæµç¨‹
  1. **åˆå§‹åŒ– (Initialize)**: åœ¨å¯åŠ¨æ—¶ï¼ŒåŠ è½½æ‰€æœ‰é…ç½®ï¼Œè¿æ¥æ•°æ®åº“ï¼Œå¹¶å‡†å¤‡å¥½å¤§è¯­è¨€æ¨¡å‹ (GPT-4o)ã€åµŒå…¥æ¨¡å‹å’Œå‘é‡æ£€ç´¢å™¨ã€‚
  2. **æ„å»ºRAGé“¾ (Build RAG Chain)**: ä½¿ç”¨ LangChain Expression Language (LCEL) å®šä¹‰ä¸€ä¸ªæ¸…æ™°çš„ã€å¯æµå¼å¤„ç†çš„é—®ç­”é€»è¾‘é“¾ã€‚
  3. **æä¾›Webç•Œé¢ (Provide Web UI)**: å¯åŠ¨ä¸€ä¸ª Gradio æœåŠ¡ï¼Œåˆ›å»ºä¸€ä¸ªç”¨æˆ·å‹å¥½çš„èŠå¤©çª—å£ã€‚
  4. å¤„ç†ç”¨æˆ·è¯·æ±‚ (Handle User Request)
     - æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ã€‚
     - **æ£€ç´¢ (Retrieve)**: å°†é—®é¢˜å‘é‡åŒ–ï¼Œå¹¶åœ¨ `pgvector` ä¸­å¿«é€Ÿæ‰¾åˆ°æœ€ç›¸ä¼¼çš„ N ä¸ªæ–‡æœ¬å—ï¼ˆå³æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼‰ã€‚
     - **å¢å¼º (Augment)**: å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å’ŒåŸå§‹é—®é¢˜ç»„åˆæˆä¸€ä¸ªè¯¦ç»†çš„æç¤º (Prompt)ã€‚
     - **ç”Ÿæˆ (Generate)**: å°†è¿™ä¸ªå¢å¼ºåçš„æç¤ºå‘é€ç»™ GPT-4oï¼Œè®©å®ƒåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”ã€‚
     - **æµå¼è¿”å› (Stream)**: å°† GPT-4o ç”Ÿæˆçš„ç­”æ¡ˆä»¥æµçš„å½¢å¼å®æ—¶ä¼ è¾“å›å‰ç«¯ï¼Œå®ç°æ‰“å­—æœºæ•ˆæœã€‚

è¿è¡Œï¼š

```sh
# python app.py
2025-08-16 18:59:23 - INFO - ğŸš€ åº”ç”¨å¼€å§‹å¯åŠ¨...
2025-08-16 18:59:23 - INFO - âœ… .env æ–‡ä»¶åŠ è½½æˆåŠŸ
2025-08-16 18:59:23 - INFO - ğŸ‘ æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®åŠ è½½å®Œæ¯•
2025-08-16 18:59:23 - INFO - ğŸ”— æ­£åœ¨è¿æ¥åˆ°æ•°æ®åº“: localhost:5432/pgvector
2025-08-16 18:59:23 - INFO - ğŸ‰ æ•°æ®åº“è¿æ¥æˆåŠŸï¼
2025-08-16 18:59:23 - INFO - ğŸ§  æ­£åœ¨åˆå§‹åŒ– OpenAI æ¨¡å‹...
2025-08-16 18:59:23 - INFO - ğŸ¤– LLM å’Œ Embedding æ¨¡å‹åˆå§‹åŒ–å®Œæˆ
2025-08-16 18:59:23 - INFO - ğŸ“š æ­£åœ¨è¿æ¥åˆ°å‘é‡é›†åˆ: 'mqtt_docs'
/root/project/mqtt-rag-project/app.py:64: LangChainPendingDeprecationWarning: This class is pending deprecation and may be removed in a future version. You can swap to using the `PGVector` implementation in `langchain_postgres`. Please read the guidelines in the doc-string of this class to follow prior to migrating as there are some differences between the implementations. See <https://github.com/langchain-ai/langchain-postgres> for details about the new implementation.
  vectorstore = PGVector(
/root/project/mqtt-rag-project/app.py:64: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. 
  vectorstore = PGVector(
2025-08-16 18:59:23 - INFO - âœ… å‘é‡å­˜å‚¨å’Œæ£€ç´¢å™¨å‡†å¤‡å°±ç»ª
2025-08-16 18:59:23 - INFO - â›“ï¸ æ­£åœ¨æ„å»º RAG é“¾...
2025-08-16 18:59:23 - INFO - âœ… RAG é“¾æ„å»ºå®Œæˆ
2025-08-16 18:59:23 - INFO - ğŸŒ å‡†å¤‡å¯åŠ¨ Gradio Web UI...
/root/project/mqtt-rag-project/app.py:147: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.
  chatbot=gr.Chatbot(height=600),
/usr/local/lib/python3.11/site-packages/gradio/chat_interface.py:321: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.
  warnings.warn(
* Running on local URL:  http://127.0.0.1:7860
2025-08-16 18:59:24 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events "HTTP/1.1 200 OK"
2025-08-16 18:59:24 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ "HTTP/1.1 200 OK"
* To create a public link, set `share=True` in `launch()`.
2025-08-16 18:59:26 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version "HTTP/1.1 200 OK"
```

æœåŠ¡æˆåŠŸå¯åŠ¨äº†ï¼Œçœ‹ä¸‹webé¡µé¢ï¼š

![image-20250816190128801](image-20250816190128801.png)

ç°åœ¨è®©æˆ‘ä»¬æé—®å‡ ä¸ªMQTTç›¸å…³çš„çŸ¥è¯†ç‚¹ï¼Œçœ‹ä¸‹æœ‰æ²¡æœ‰æˆåŠŸæ£€ç´¢åˆšåˆšåˆ›å»ºçš„çŸ¥è¯†åº“ï¼Œæ—¥å¿—é‡Œé¢ä¼šè¯¦ç»†æ‰“å°æ•°æ®ã€‚

![image-20250816190506250](image-20250816190506250.png)

æ—¥å¿—è¾“å‡ºï¼š

```sh
2025-08-16 19:04:15 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ "HTTP/1.1 200 OK"
2025-08-16 19:04:15 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version "HTTP/1.1 200 OK"
2025-08-16 19:04:24 - INFO - ğŸ’¬ æ”¶åˆ°ç”¨æˆ·æ–°é—®é¢˜: 'mqtt æ˜¯ä»€ä¹ˆï¼Ÿ'
2025-08-16 19:04:24 - INFO - âœï¸ å¼€å§‹å‘ç”¨æˆ·æµå¼ä¼ è¾“å›ç­”...
2025-08-16 19:04:25 - INFO - HTTP Request: POST https://api.chatanywhere.tech/embeddings "HTTP/1.1 200 OK"
2025-08-16 19:04:25 - INFO - ğŸ” å‘é‡æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° 10 ä¸ªç›¸å…³æ–‡æ¡£:
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 1 (é¡µç : 2): 'Chapter 1: Introduction to MQTT MQTT is a lightweight messaging protocol originally designed for communication in constr...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 2 (é¡µç : 4): 'While it formerly stood for MQ Telemetry  Transport, where MQ referred to the MQ  Series, a product IBM developed to sup...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 3 (é¡µç : 4): 'cases. Over the next ten years, IBM used the protocol internally until  they released MQTT 3.1 as a royalty-free version...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 4 (é¡µç : 4): 'Real-World Applications and Use Cases of  MQTT: An Overview MQTT is used extensively in IoT, Industrial IoT (IIoT), and ...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 5 (é¡µç : 77): 'managed cloud MQTT broker. Explore them now! MQTT HTTP Full name MQTT (the OASIS standardization  group decided it would...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 6 (é¡µç : 3): 'Another important aspect of the protocol is that MQTT is  extremely easy to implement on the client side. Ease of use  w...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 7 (é¡µç : 8): 'established, clients can publish messages to topics  or subscribe to topics to receive messages from other  clients. â€¢ K...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 8 (é¡µç : 20): 'IoT devices. The foundation of this communication is  the MQTT connection, which enables devices to securely  and reliab...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 9 (é¡µç : 69): 'and brokers. Its Keep Alive mechanism minimizes energy and  bandwidth usage, enabling users to establish cost-effective,...'
2025-08-16 19:04:25 - INFO -   ğŸ“„ æ–‡æ¡£ 10 (é¡µç : 3): 'MQTT uses a binary message format for communication between clients and servers (brokers). This is in contrast to other ...'
2025-08-16 19:04:27 - INFO - HTTP Request: POST https://api.chatanywhere.tech/chat/completions "HTTP/1.1 200 OK"
2025-08-16 19:04:27 - INFO - âœ… æµå¼ä¼ è¾“å®Œæˆ
2025-08-16 19:04:48 - INFO - ğŸ’¬ æ”¶åˆ°ç”¨æˆ·æ–°é—®é¢˜: 'mqtt æœ‰ä»€ä¹ˆä¼˜ç‚¹ï¼Ÿ'
2025-08-16 19:04:48 - INFO - âœï¸ å¼€å§‹å‘ç”¨æˆ·æµå¼ä¼ è¾“å›ç­”...
2025-08-16 19:04:48 - INFO - HTTP Request: POST https://api.chatanywhere.tech/embeddings "HTTP/1.1 200 OK"
2025-08-16 19:04:48 - INFO - ğŸ” å‘é‡æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° 10 ä¸ªç›¸å…³æ–‡æ¡£:
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 1 (é¡µç : 3): 'Another important aspect of the protocol is that MQTT is  extremely easy to implement on the client side. Ease of use  w...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 2 (é¡µç : 56): 'protocol more robust and efficient. Who Needs More Client Feedback While Using  MQTT? Over the years, MQTT has become a ...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 3 (é¡µç : 51): 'IoT Standard With its rich feature set, MQTT 5 has cemented its place  as the go-to choice for diverse IoT use cases, su...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 4 (é¡µç : 50): '1. Better Error Handling for More Robust Systems 2. More Scalability for Cloud Native Computing 3. Greater Flexibility a...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 5 (é¡µç : 51): 'firmware version of the device platform can be added to the  message header, facilitating analysis and processing by the...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 6 (é¡µç : 50): 'delivered within this time frame, itâ€™s automatically deleted. This  feature is particularly useful in ensuring that netw...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 7 (é¡µç : 6): 'communication participants all endure in this latest  version. However, several foundational mechanics have  been added ...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 8 (é¡µç : 3): 'supports persistent sessions between devices and  servers, enhancing message reliability by ensuring  that messages are ...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 9 (é¡µç : 2): 'Chapter 1: Introduction to MQTT MQTT is a lightweight messaging protocol originally designed for communication in constr...'
2025-08-16 19:04:48 - INFO -   ğŸ“„ æ–‡æ¡£ 10 (é¡µç : 45): 'objectives for MQTT 5, aimed at enhancing scalability,  formalizing common patterns such as capability discovery and  re...'
2025-08-16 19:04:53 - INFO - HTTP Request: POST https://api.chatanywhere.tech/chat/completions "HTTP/1.1 200 OK"
2025-08-16 19:04:54 - INFO - âœ… æµå¼ä¼ è¾“å®Œæˆ
```

å¯ä»¥çœ‹åˆ°ï¼Œå›ç­”è¿‡ç¨‹ä¸­ç¡®å®æ£€ç´¢äº†å‘é‡æ•°æ®åº“ã€‚

åˆ°æ­¤ä¸€ä¸ªå®Œæ•´RAGé¡¹ç›®å°±å®Œæˆäº†ï¼

ğŸ‰ğŸ‰ğŸ‰
